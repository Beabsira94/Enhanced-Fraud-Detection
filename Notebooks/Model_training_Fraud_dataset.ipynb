{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beabsira94/Enhanced-Fraud-Detection/blob/Task-2/Notebooks/Model_training_Fraud_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "In this notebook, we embark on **Task 2** of the project, focusing on **Model Building and Training** for both credit card and fraud detection datasets. This process involves preparing the data by separating features and target variables, performing a train-test split, and selecting several models for comparison, including Logistic Regression, Decision Trees, Random Forest, Gradient Boosting, and neural network architectures like MLP, CNN, RNN, and LSTM. Each model will be trained, evaluated, and optimized for performance. Additionally, we incorporate MLOps practices by using tools like MLflow for experiment tracking, model versioning, and parameter logging, ensuring a robust and organized workflow."
      ],
      "metadata": {
        "id": "V4Djl6f-8KjX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Y6LbLj6ZYA",
        "outputId": "fad0c148-850e-4e18-8431-28e4c1b6e8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/notebooks\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to start by mounting our drive."
      ],
      "metadata": {
        "id": "67Ws8ycKBhdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNCiYtK86hhX",
        "outputId": "f1934498-b563-4cc0-b266-8adad144225c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctweGqmM7FTD",
        "outputId": "2de06bc2-d1cd-4ef5-8be5-a773f525a4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to start our model training using the Fraud dataset."
      ],
      "metadata": {
        "id": "pjAmElkX7Ikg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AFnYK1yRHcgL",
        "outputId": "568aac87-7992-4e63-dd8e-cb10b790b5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.17.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.17.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.36.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries and the dataset Fraud_dataset.csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/Data/df_merged.csv\")\n",
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNu9TK6gCU1k",
        "outputId": "54b94593-991a-482f-ef91-932ad1173b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of         user_id      signup_time    purchase_time  purchase_value  \\\n",
            "0         22058  2/24/2015 22:55   4/18/2015 2:47              34   \n",
            "1        333320   6/7/2015 20:39    6/8/2015 1:38              16   \n",
            "2          1359   1/1/2015 18:52   1/1/2015 18:52              15   \n",
            "3          1359   1/1/2015 18:52   1/1/2015 18:52              15   \n",
            "4          1359   1/1/2015 18:52   1/1/2015 18:52              15   \n",
            "...         ...              ...              ...             ...   \n",
            "208076   360761   2/10/2015 6:39    6/3/2015 8:18              13   \n",
            "208077   345170   1/27/2015 3:03   3/29/2015 0:30              43   \n",
            "208078   274471  5/15/2015 17:43  5/26/2015 12:24              35   \n",
            "208079   368416   3/3/2015 23:07   5/20/2015 7:07              40   \n",
            "208080   207709   7/9/2015 20:06    9/7/2015 9:34              46   \n",
            "\n",
            "            device_id source browser  sex  age  ip_address  class  \\\n",
            "0       QVPSPJUOCKZAR    SEO  Chrome    1   39   732758368      0   \n",
            "1       EOGFQPIZPYXFZ    Ads  Chrome    0   53   350311387      0   \n",
            "2       YSSKYOSJHPPLJ    SEO   Opera    1   53  2621473820      1   \n",
            "3       YSSKYOSJHPPLJ    SEO   Opera    1   53  2621473820      1   \n",
            "4       YSSKYOSJHPPLJ    SEO   Opera    1   53  2621473820      1   \n",
            "...               ...    ...     ...  ...  ...         ...    ...   \n",
            "208076  EFCFFMUKFRDHJ    SEO  Safari    0   42   874065719      0   \n",
            "208077  XPSKTWGPWINLR    SEO  Chrome    1   28  3451154526      1   \n",
            "208078  LYSFABUCPCGBA    SEO  Safari    1   32  2439047221      0   \n",
            "208079  MEQHCSJUBRBFE    SEO      IE    0   26  2748470523      0   \n",
            "208080  CMCXFGRHYSTVJ    SEO  Chrome    1   37  3601174708      0   \n",
            "\n",
            "              country  hour_of_day  day_of_week  transaction_frequency  \\\n",
            "0               Japan            2            6                      1   \n",
            "1       United States            1            1                      1   \n",
            "2       United States           18            4                     12   \n",
            "3       United States           18            4                     12   \n",
            "4       United States           18            4                     12   \n",
            "...               ...          ...          ...                    ...   \n",
            "208076  United States            8            3                      1   \n",
            "208077  United States            0            7                      1   \n",
            "208078    Netherlands           12            2                      1   \n",
            "208079          Japan            7            3                      1   \n",
            "208080  United States            9            1                      1   \n",
            "\n",
            "        normalized_purchase  \n",
            "0                  0.304878  \n",
            "1                  0.085366  \n",
            "2                  0.073171  \n",
            "3                  0.073171  \n",
            "4                  0.073171  \n",
            "...                     ...  \n",
            "208076             0.048780  \n",
            "208077             0.414634  \n",
            "208078             0.317073  \n",
            "208079             0.378049  \n",
            "208080             0.451220  \n",
            "\n",
            "[208081 rows x 16 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to conduct a last cleaning check before proceeding to our models to be trained."
      ],
      "metadata": {
        "id": "wo_NR1YDC_dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Or6fg-qDIsz",
        "outputId": "4c5699fc-4105-43c5-ffab-e5c92ec3d0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_id                  0\n",
            "signup_time              0\n",
            "purchase_time            0\n",
            "purchase_value           0\n",
            "device_id                0\n",
            "source                   0\n",
            "browser                  0\n",
            "sex                      0\n",
            "age                      0\n",
            "ip_address               0\n",
            "class                    0\n",
            "country                  0\n",
            "hour_of_day              0\n",
            "day_of_week              0\n",
            "transaction_frequency    0\n",
            "normalized_purchase      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We are going to proceed to splitting the data for our models.**"
      ],
      "metadata": {
        "id": "TY3yrrF7FLo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Separate the features (X) and the target variable (y)\n",
        "X = df.drop(columns=['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address'])\n",
        "y = df['class']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Set the MLflow tracking URI to the specified directory\n",
        "mlflow.set_tracking_uri(\"/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/Log mlflow\")\n",
        "\n",
        "# Create or set an experiment\n",
        "# If the experiment doesn't exist, it will be created\n",
        "# If it exists, MLflow will use the existing experiment\n",
        "mlflow.set_experiment(\"Fraud Detection Experiment\")  # Replace with your desired experiment name\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run():\n",
        "    # Log the dataset split\n",
        "    mlflow.log_param(\"test_size\", 0.3)\n",
        "    mlflow.log_param(\"random_state\", 42)\n",
        "\n",
        "    # Log the features and target shapes\n",
        "    mlflow.log_param(\"X_train_shape\", X_train.shape)\n",
        "    mlflow.log_param(\"X_test_shape\", X_test.shape)\n",
        "    mlflow.log_param(\"y_train_shape\", y_train.shape)\n",
        "    mlflow.log_param(\"y_test_shape\", y_test.shape)\n",
        "\n",
        "    # Optionally: Save the train and test datasets as artifacts\n",
        "    # mlflow.log_artifact(\"X_train.csv\")\n",
        "    # mlflow.log_artifact(\"X_test.csv\")\n",
        "\n",
        "print(\"Train and test data split successfully and logged to MLflow.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgeMumoJJs9w",
        "outputId": "2b0ea2d5-4f21-4ce8-cc5e-27c6d20a276a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/24 17:20:20 INFO mlflow.tracking.fluent: Experiment with name 'Fraud Detection Experiment' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and test data split successfully and logged to MLflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We are going to train and evaluate Logistic Regression, Gradient Boosting, Convolutional Neural Network(CNN) and Long Short-Term Memory models.**"
      ],
      "metadata": {
        "id": "sBz3l6PMKHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow scikit-learn xgboost tensorflow pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9mjVpQigKbSB",
        "outputId": "1af9c5c3-a4e7-4cc2-c2cf-74727c6bd11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.17.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.17.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.36.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Ensure your data frame 'df' is already loaded and split\n",
        "X = df.drop(columns=['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address'])\n",
        "y = df['class']\n",
        "\n",
        "# Encode categorical features in X\n",
        "label_encoder = LabelEncoder()\n",
        "for column in X.select_dtypes(include=['object']).columns:\n",
        "    X[column] = label_encoder.fit_transform(X[column])\n",
        "\n",
        "# Now proceed with the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Set the MLflow tracking URI and experiment name\n",
        "mlflow.set_tracking_uri(\"/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/Log mlflow\")\n",
        "mlflow.set_experiment(\"fraud_detection_experiment\")\n",
        "\n",
        "# Function to log model and metrics\n",
        "def log_model_and_metrics(model, model_name, X_train, y_train, X_test, y_test):\n",
        "    with mlflow.start_run() as run:\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        print(f\"{model_name} Accuracy: {accuracy}\")\n",
        "\n",
        "        # Log metrics, parameters, and the model\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_param(\"model_name\", model_name)\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "        # Print the run ID for reference\n",
        "        run_id = run.info.run_id\n",
        "        print(f\"{model_name} Run ID: {run_id}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "# 1. Logistic Regression\n",
        "logistic_model = LogisticRegression(max_iter=100)\n",
        "logistic_accuracy = log_model_and_metrics(logistic_model, \"Logistic Regression\", X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 2. Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_accuracy = log_model_and_metrics(gb_model, \"Gradient Boosting\", X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 3. Convolutional Neural Network (CNN)\n",
        "# Reshape X_train and X_test for CNN (1D CNN input)\n",
        "X_train_cnn = np.expand_dims(X_train.values, axis=-1)\n",
        "X_test_cnn = np.expand_dims(X_test.values, axis=-1)\n",
        "\n",
        "cnn_model = models.Sequential()\n",
        "cnn_model.add(layers.Conv1D(32, 2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(layers.Flatten())\n",
        "cnn_model.add(layers.Dense(64, activation='relu'))\n",
        "cnn_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict and evaluate CNN\n",
        "cnn_predictions = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
        "cnn_accuracy = accuracy_score(y_test, cnn_predictions)\n",
        "print(f\"CNN Accuracy: {cnn_accuracy}\")\n",
        "\n",
        "# Log CNN model\n",
        "with mlflow.start_run() as run:\n",
        "    mlflow.log_metric(\"accuracy\", cnn_accuracy)\n",
        "    mlflow.log_param(\"model_name\", \"Convolutional Neural Network\")\n",
        "    mlflow.tensorflow.log_model(cnn_model, \"cnn_model\")\n",
        "    print(f\"CNN Run ID: {run.info.run_id}\")\n",
        "\n",
        "# 4. Long Short-Term Memory (LSTM)\n",
        "# Reshape X_train and X_test for LSTM (3D input)\n",
        "X_train_lstm = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_lstm = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "lstm_model = models.Sequential()\n",
        "lstm_model.add(layers.LSTM(50, input_shape=(X_train_lstm.shape[1], 1)))\n",
        "lstm_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict and evaluate LSTM\n",
        "lstm_predictions = (lstm_model.predict(X_test_lstm) > 0.5).astype(\"int32\")\n",
        "lstm_accuracy = accuracy_score(y_test, lstm_predictions)\n",
        "print(f\"LSTM Accuracy: {lstm_accuracy}\")\n",
        "\n",
        "# Log LSTM model\n",
        "with mlflow.start_run() as run:\n",
        "    mlflow.log_metric(\"accuracy\", lstm_accuracy)\n",
        "    mlflow.log_param(\"model_name\", \"Long Short-Term Memory\")\n",
        "    mlflow.tensorflow.log_model(lstm_model, \"lstm_model\")\n",
        "    print(f\"LSTM Run ID: {run.info.run_id}\")\n",
        "\n",
        "# Save all models for later deployment\n",
        "model_directory = \"/content/drive/MyDrive/Colab Notebooks/Enhanced-Fraud-Detection/Models\"\n",
        "with open(f\"{model_directory}/logistic_regression_model.pkl\", 'wb') as f:\n",
        "    pickle.dump(logistic_model, f)\n",
        "\n",
        "with open(f\"{model_directory}/gradient_boosting_model.pkl\", 'wb') as f:\n",
        "    pickle.dump(gb_model, f)\n",
        "\n",
        "cnn_model.save(f\"{model_directory}/cnn_model.h5\")  # Save CNN model\n",
        "lstm_model.save(f\"{model_directory}/lstm_model.h5\")  # Save LSTM model\n",
        "\n",
        "# Show results for all models\n",
        "results = {\n",
        "    \"Logistic Regression\": logistic_accuracy,\n",
        "    \"Gradient Boosting\": gb_accuracy,\n",
        "    \"CNN\": cnn_accuracy,\n",
        "    \"LSTM\": lstm_accuracy,\n",
        "}\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "for model_name, accuracy in results.items():\n",
        "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
        "\n",
        "# Set up ngrok to access MLflow UI\n",
        "ngrok.set_auth_token(\"2ntN0XY0zsArjXyzy66uf6UKlcw_2ZSxz1TfmtasmErCsKMiG\")  # Replace with your ngrok token\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"MLflow UI available at: {public_url}\")\n",
        "\n",
        "# Run MLflow UI\n",
        "!mlflow ui --port 5000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitPIsA3joeu",
        "outputId": "a1b152f9-26b8-4359-d146-49793bcb7c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:20:39 INFO mlflow.tracking.fluent: Experiment with name 'fraud_detection_experiment' does not exist. Creating a new experiment.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9343372046455747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:20:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Run ID: ec767abd80dc4bd3b356a726c3315c1c\n",
            "Gradient Boosting Accuracy: 0.9400240288346016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:21:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Run ID: 7529ff1a5c654eab93624c5447aa1659\n",
            "\u001b[1m1951/1951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:22:48 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN Accuracy: 0.9389347216659992\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:22:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN Run ID: 11251745cc2f48d8a876d932816a0f2d\n",
            "\u001b[1m1951/1951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:26:15 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Accuracy: 0.9434040849018822\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/24 17:26:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Run ID: adc82d3ab7b247f1992027dd13d0af31\n",
            "\n",
            "Model Performance:\n",
            "Logistic Regression Accuracy: 0.9343372046455747\n",
            "Gradient Boosting Accuracy: 0.9400240288346016\n",
            "CNN Accuracy: 0.9389347216659992\n",
            "LSTM Accuracy: 0.9434040849018822\n",
            "MLflow UI available at: NgrokTunnel: \"https://f0aa-34-19-27-92.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "[2024-10-24 17:26:23 +0000] [10395] [INFO] Starting gunicorn 23.0.0\n",
            "[2024-10-24 17:26:23 +0000] [10395] [INFO] Listening at: http://127.0.0.1:5000 (10395)\n",
            "[2024-10-24 17:26:23 +0000] [10395] [INFO] Using worker: sync\n",
            "[2024-10-24 17:26:23 +0000] [10400] [INFO] Booting worker with pid: 10400\n",
            "[2024-10-24 17:26:23 +0000] [10401] [INFO] Booting worker with pid: 10401\n",
            "[2024-10-24 17:26:24 +0000] [10402] [INFO] Booting worker with pid: 10402\n",
            "[2024-10-24 17:26:24 +0000] [10403] [INFO] Booting worker with pid: 10403\n",
            "[2024-10-24 17:49:42 +0000] [10395] [INFO] Handling signal: int\n",
            "\n",
            "Aborted!\n",
            "[2024-10-24 17:49:42 +0000] [10400] [INFO] Worker exiting (pid: 10400)\n",
            "[2024-10-24 17:49:42 +0000] [10403] [INFO] Worker exiting (pid: 10403)\n",
            "[2024-10-24 17:49:42 +0000] [10402] [INFO] Worker exiting (pid: 10402)\n",
            "[2024-10-24 17:49:42 +0000] [10401] [INFO] Worker exiting (pid: 10401)\n",
            "[2024-10-24 17:49:43 +0000] [10395] [INFO] Shutting down: Master\n"
          ]
        }
      ]
    }
  ]
}